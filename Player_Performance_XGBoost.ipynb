{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "15WIeQeux0reYq2B5SD5YOi1ldnektKve",
      "authorship_tag": "ABX9TyMpgvDv2Vu9c0pJWWp0Z87z"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VVxdV0KVYUE3",
        "outputId": "d1331703-f56e-4ad0-8291-6289c98777f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.11/dist-packages (2.1.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from xgboost) (1.26.4)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.11/dist-packages (from xgboost) (2.21.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from xgboost) (1.13.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install xgboost"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score, f1_score, accuracy_score\n",
        "from sklearn.metrics import make_scorer, f1_score, accuracy_score, mean_absolute_error  # Import mean_absolute_error\n",
        "from sklearn.dummy import DummyClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import xgboost as xgb"
      ],
      "metadata": {
        "id": "J2gCClG8Youh"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load datasets\n",
        "def load_data():\n",
        "    df_20_21 = pd.read_csv('/content/drive/MyDrive/CollabData/Player_Prediction/df_20_21.csv')\n",
        "    df_21_22 = pd.read_csv('/content/drive/MyDrive/CollabData/Player_Prediction/df_21_22.csv')\n",
        "    df_22_23 = pd.read_csv('/content/drive/MyDrive/CollabData/Player_Prediction/df_22_23.csv')\n",
        "    df_23_24 = pd.read_csv('/content/drive/MyDrive/CollabData/Player_Prediction/df_23_24.csv')\n",
        "    df_24_25 = pd.read_csv('/content/drive/MyDrive/CollabData/Player_Prediction/df_24_25.csv')\n",
        "    return df_20_21,df_21_22,df_22_23, df_23_24, df_24_25"
      ],
      "metadata": {
        "id": "BhPSUlEmYqs4"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess data for LSTM\n",
        "def preprocess_data_xgb(df):\n",
        "    # Add time_idx for temporal ordering\n",
        "    df = df.reset_index()  # Reset index to ensure uniqueness\n",
        "    df['time_idx'] = pd.factorize(df['MP'])[0]\n",
        "\n",
        "    # Fill NaN values in relevant columns\n",
        "    df.fillna(0, inplace=True)\n",
        "\n",
        "    # Feature Engineering\n",
        "    df['G+A'] = df['Gls'] + df['Ast']\n",
        "    df['G-PK'] = df['Gls'] - df['PK']\n",
        "    df['G+A-PK'] = df['G+A'] - df['PK']\n",
        "\n",
        "    df['xG+xAG'] = df['xG'] + df['xAG']\n",
        "    df['npxG+xAG'] = df['npxG'] + df['xAG']\n",
        "\n",
        "    # Define a weighted Performance Index\n",
        "    df['Performance_Index'] = (\n",
        "        df['G+A-PK'] * 0.35 +    # Emphasis on actual goal contributions\n",
        "        df['xG+xAG'] * 0.25 +    # Expected goal contributions\n",
        "        df['PrgC'] * 0.15 +      # Progressive carries\n",
        "        df['PrgP'] * 0.15 +      # Progressive passes\n",
        "        df['PrgR'] * 0.1         # Progressive receptions\n",
        "    )\n",
        "\n",
        "    # Future Performance Potential based on trends (without 'Min')\n",
        "    df['Future_Potential'] = (\n",
        "        (df['MP'] / (df['MP'].mean() + 1)) * 0.4 +  # Playing time influence using 'MP'\n",
        "        df.groupby('Player')['Performance_Index'].transform(lambda x: x.diff().fillna(0)) * 0.6  # Performance trends\n",
        "    )\n",
        "\n",
        "    features = [\n",
        "        \"MP\", \"Gls\", \"Ast\", \"G+A-PK\", \"xG\", \"xAG\", \"xG+xAG\",\n",
        "        \"npxG\", \"npxG+xAG\", \"PrgC\", \"PrgP\", \"PrgR\", \"Tkl\", \"Int\", \"Blocks\",\n",
        "        \"Performance_Index\", \"Future_Potential\"\n",
        "    ]\n",
        "\n",
        "    # Verify uniqueness of the index\n",
        "    if not df.index.is_unique:\n",
        "        raise ValueError(\"Data index must be unique.\")\n",
        "\n",
        "    return df[features], df[\"Performance_Index\"]"
      ],
      "metadata": {
        "id": "f_kXtnFFY1oA"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train XGBoost model\n",
        "def train_xgb(X_train, y_train):\n",
        "    model = xgb.XGBRegressor(\n",
        "        objective='reg:squarederror',  # Regression objective\n",
        "        n_estimators=100,  # Number of boosting rounds (trees)\n",
        "        learning_rate=0.1,  # Step size shrinkage used in update to prevents overfitting\n",
        "        max_depth=3,  # Maximum depth of a tree\n",
        "        subsample=0.8,  # Subsample ratio of the training instance\n",
        "        colsample_bytree=0.8  # Subsample ratio of columns when constructing each tree\n",
        "    )\n",
        "\n",
        "    model.fit(X_train, y_train)\n",
        "    return model"
      ],
      "metadata": {
        "id": "JFlDiOaEY_JF"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_xgboost(model, X_test, y_test, df_test): # Pass df_test to the function\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        predictions = model.predict(X_test)\n",
        "\n",
        "    raw_predictions = predictions\n",
        "    predictions = raw_predictions.cpu().numpy() # Remove the index and prediction key to get the raw predictions\n",
        "\n",
        "    num_test_samples = len(df_test['G+A'])  # Assuming df_test is defined globally\n",
        "\n",
        "    if len(predictions) < num_test_samples:\n",
        "        predictions = np.pad(predictions, (0, num_test_samples - len(predictions)), mode='edge')\n",
        "    elif len(predictions) > num_test_samples:\n",
        "        predictions = predictions[:num_test_samples]  # Truncate excess values\n",
        "    return predictions"
      ],
      "metadata": {
        "id": "FEItoZe4ZaK7"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Main workflow\n",
        "def main():\n",
        "    df_20_21, df_21_22, df_22_23, df_23_24, df_24_25 = load_data()\n",
        "\n",
        "    df_train = pd.concat([df_20_21, df_21_22, df_22_23, df_23_24])\n",
        "    df_test = df_24_25\n",
        "\n",
        "    X_train, y_train = preprocess_data_xgb(df_train)\n",
        "    X_test, y_test = preprocess_data_xgb(df_test)\n",
        "\n",
        "    model = train_xgb(X_train, y_train)\n",
        "    predictions = evaluate_xgb(model, X_test, y_test)\n",
        "\n",
        "    actual = df_test['G+A'].values\n",
        "\n",
        "    display_metrics(predictions, actual)\n",
        "\n",
        "    print(predictions)"
      ],
      "metadata": {
        "id": "rW-S0b9FZyUj"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Execute the workflow\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "s6premmUZ1br"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}