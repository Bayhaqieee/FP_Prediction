{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General Prediction Model for Football Players"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This prediction model evaluates a player's overall performance and impact based on the following aggregated metrics\n",
    "\n",
    "---\n",
    "\n",
    "*Performance Index*:\n",
    "\n",
    "A weighted index combining:\n",
    "- Goals and assists (G+A)\n",
    "- xG+xAG (expected contributions)\n",
    "- PrgC, PrgP, PrgR (progression metrics)\n",
    "- Defensive contributions (Tkl, Int, Blocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\adity\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pytorch_forecasting\\models\\base_model.py:27: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from pytorch_forecasting import TemporalFusionTransformer, TimeSeriesDataSet\n",
    "from pytorch_forecasting.data import GroupNormalizer\n",
    "from pytorch_lightning import Trainer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "def load_data():\n",
    "    df_22_23 = pd.read_csv('Data/df_22_23.csv')\n",
    "    df_23_24 = pd.read_csv('Data/df_23_24.csv')\n",
    "    df_24_25 = pd.read_csv('Data/df_24_25.csv')\n",
    "    return df_22_23, df_23_24, df_24_25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess data for TFT\n",
    "def preprocess_data_tft(df):\n",
    "    # Add time_idx for temporal ordering\n",
    "    df = df.reset_index()  # Reset index to ensure uniqueness\n",
    "    df['time_idx'] = pd.factorize(df['MP'])[0]\n",
    "\n",
    "    # Feature Engineering\n",
    "    df['G+A'] = df['Gls'] + df['Ast']\n",
    "    df['xG+xAG'] = df['xG'] + df['xAG']\n",
    "\n",
    "    df['Performance_Index'] = (\n",
    "        df['G+A'] * 0.4 + \n",
    "        df['xG+xAG'] * 0.3 + \n",
    "        (df['PrgC'] + df['PrgP'] + df['PrgR']) * 0.2 + \n",
    "        (df['Tkl'] + df['Int'] + df['Blocks']) * 0.1\n",
    "    )\n",
    "\n",
    "    df['Future_Potential'] = (\n",
    "        (1 / (df['Age'] + 1)) * df['MP'] + \n",
    "        df.groupby('Player')['G+A'].transform(lambda x: x.diff().fillna(0))\n",
    "    )\n",
    "\n",
    "    # Verify uniqueness of the index\n",
    "    if not df.index.is_unique:\n",
    "        raise ValueError(\"Data index must be unique.\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create TimeSeriesDataSet\n",
    "def create_tft_dataset(df):\n",
    "    df = preprocess_data_tft(df)\n",
    "    \n",
    "    max_prediction_length = 1  # predict one season ahead\n",
    "    max_encoder_length = 3  # use data from the last three seasons\n",
    "    \n",
    "    training = TimeSeriesDataSet(\n",
    "        df,\n",
    "        time_idx=\"time_idx\",\n",
    "        target=\"G+A\",\n",
    "        group_ids=[\"Player\"],\n",
    "        max_encoder_length=max_encoder_length,\n",
    "        max_prediction_length=max_prediction_length,\n",
    "        static_categoricals=[\"Player\"],\n",
    "        static_reals=[\"Age\"],\n",
    "        time_varying_known_reals=[\"time_idx\"],\n",
    "        time_varying_unknown_reals=[\"Gls\", \"Ast\", \"xG\", \"xAG\", \"PrgC\", \"PrgP\", \"PrgR\", \"Tkl\", \"Int\", \"Blocks\", \"Performance_Index\", \"Future_Potential\"],\n",
    "        add_relative_time_idx=True,\n",
    "        add_target_scales=True,\n",
    "        add_encoder_length=True,\n",
    "        allow_missing_timesteps=True\n",
    "    )\n",
    "\n",
    "    return training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train TFT model\n",
    "def train_tft(training):\n",
    "    trainer = Trainer(gpus=1 if torch.cuda.is_available() else 0, max_epochs=30)\n",
    "\n",
    "    tft = TemporalFusionTransformer.from_dataset(\n",
    "        training,\n",
    "        learning_rate=0.03,\n",
    "        hidden_size=32,\n",
    "        attention_head_size=4,\n",
    "        dropout=0.1,\n",
    "        hidden_continuous_size=16,\n",
    "        output_size=7,  # for regression\n",
    "        loss=torch.nn.MSELoss(),\n",
    "    )\n",
    "\n",
    "    trainer.fit(tft, train_dataloaders=training.to_dataloader(train=True, batch_size=64))\n",
    "    return tft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate TFT model\n",
    "def evaluate_tft(tft, test_dataloader):\n",
    "    predictions = tft.predict(test_dataloader)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main workflow\n",
    "def main():\n",
    "    df_22_23, df_23_24, df_24_25 = load_data()\n",
    "\n",
    "    df_train = pd.concat([df_22_23, df_23_24])\n",
    "    df_test = df_24_25\n",
    "\n",
    "    training = create_tft_dataset(df_train)\n",
    "    testing = create_tft_dataset(df_test)\n",
    "\n",
    "    tft = train_tft(training)\n",
    "\n",
    "    test_dataloader = testing.to_dataloader(train=False, batch_size=64)\n",
    "    predictions = evaluate_tft(tft, test_dataloader)\n",
    "\n",
    "    print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\adity\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pytorch_forecasting\\data\\timeseries.py:1301: UserWarning: Min encoder length and/or min_prediction_idx and/or min prediction length and/or lags are too large for 4320 series/groups which therefore are not present in the dataset index. This means no predictions can be made for those series. First 10 removed groups: [{'__group_id__Player': 'Aaron Ciammaglichella'}, {'__group_id__Player': 'Aaron Cresswell'}, {'__group_id__Player': 'Aaron Hickey'}, {'__group_id__Player': 'Aaron Malouda'}, {'__group_id__Player': 'Aaron Ramsdale'}, {'__group_id__Player': 'Aaron Ramsey'}, {'__group_id__Player': 'Aaron Seydel'}, {'__group_id__Player': 'Aaron Zehnter'}, {'__group_id__Player': 'Aarón Escandell'}, {'__group_id__Player': 'Aarón Martín'}]\n",
      "  warnings.warn(\n",
      "c:\\Users\\adity\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pytorch_forecasting\\data\\timeseries.py:1301: UserWarning: Min encoder length and/or min_prediction_idx and/or min prediction length and/or lags are too large for 3661 series/groups which therefore are not present in the dataset index. This means no predictions can be made for those series. First 10 removed groups: [{'__group_id__Player': 'Aaron Ciammaglichella'}, {'__group_id__Player': 'Aaron Cresswell'}, {'__group_id__Player': 'Aaron Hickey'}, {'__group_id__Player': 'Aaron Malouda'}, {'__group_id__Player': 'Aaron Ramsdale'}, {'__group_id__Player': 'Aaron Ramsey'}, {'__group_id__Player': 'Aaron Seydel'}, {'__group_id__Player': 'Aaron Wan-Bissaka'}, {'__group_id__Player': 'Aarón Escandell'}, {'__group_id__Player': 'Aarón Martín'}]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Trainer.__init__() got an unexpected keyword argument 'gpus'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Execute the workflow\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m----> 3\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[33], line 11\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m training \u001b[38;5;241m=\u001b[39m create_tft_dataset(df_train)\n\u001b[0;32m      9\u001b[0m testing \u001b[38;5;241m=\u001b[39m create_tft_dataset(df_test)\n\u001b[1;32m---> 11\u001b[0m tft \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_tft\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m test_dataloader \u001b[38;5;241m=\u001b[39m testing\u001b[38;5;241m.\u001b[39mto_dataloader(train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m)\n\u001b[0;32m     14\u001b[0m predictions \u001b[38;5;241m=\u001b[39m evaluate_tft(tft, test_dataloader)\n",
      "Cell \u001b[1;32mIn[31], line 3\u001b[0m, in \u001b[0;36mtrain_tft\u001b[1;34m(training)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_tft\u001b[39m(training):\n\u001b[1;32m----> 3\u001b[0m     trainer \u001b[38;5;241m=\u001b[39m \u001b[43mTrainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_available\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m     tft \u001b[38;5;241m=\u001b[39m TemporalFusionTransformer\u001b[38;5;241m.\u001b[39mfrom_dataset(\n\u001b[0;32m      6\u001b[0m         training,\n\u001b[0;32m      7\u001b[0m         learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.03\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     13\u001b[0m         loss\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mMSELoss(),\n\u001b[0;32m     14\u001b[0m     )\n\u001b[0;32m     16\u001b[0m     trainer\u001b[38;5;241m.\u001b[39mfit(tft, train_dataloaders\u001b[38;5;241m=\u001b[39mtraining\u001b[38;5;241m.\u001b[39mto_dataloader(train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\adity\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pytorch_lightning\\utilities\\argparse.py:70\u001b[0m, in \u001b[0;36m_defaults_from_env_vars.<locals>.insert_env_defaults\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mlist\u001b[39m(env_variables\u001b[38;5;241m.\u001b[39mitems()) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlist\u001b[39m(kwargs\u001b[38;5;241m.\u001b[39mitems()))\n\u001b[0;32m     69\u001b[0m \u001b[38;5;66;03m# all args were already moved to kwargs\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: Trainer.__init__() got an unexpected keyword argument 'gpus'"
     ]
    }
   ],
   "source": [
    "# Execute the workflow\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
